{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOvU8+fSUDqCtbzTrTMnfw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarthak-kshirsagar/ansible-playbook-gen-ai/blob/main/RAG_Ansible_Storage_Protect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WClEP3FYQeW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install ibm-watsonx-ai --upgrade\n",
        "!pip install faiss-cpu\n",
        "!pip install sentence-transformers\n",
        "!pip install ansible\n",
        "import os\n",
        "import subprocess\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from ibm_watsonx_ai import Credentials\n",
        "from ibm_watsonx_ai.foundation_models import ModelInference\n",
        "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
        "import getpass"
      ],
      "metadata": {
        "id": "bZlqPi320EGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_url = 'https://github.com/IBM/ansible-storage-protect'\n",
        "repo_dir = \"ansible-storage-protect\"\n",
        "roles_dir = os.path.join(repo_dir, \"roles\")\n",
        "\n",
        "if not os.path.exists(repo_dir):\n",
        "    print(f\"Cloning repository from {repo_url}...\")\n",
        "    subprocess.run([\"git\", \"clone\", repo_url], check=True)\n",
        "else:\n",
        "    print(\"Repository already cloned.\")\n",
        "\n",
        "\n",
        "def extract_role_contents(roles_directory):\n",
        "    \"\"\"\n",
        "    Traverse the roles directory and extract each role's README.md content.\n",
        "    Returns a dictionary mapping role names to their README content.\n",
        "    \"\"\"\n",
        "    knowledge_base = {}\n",
        "    if os.path.exists(roles_directory):\n",
        "        for role in os.listdir(roles_directory):\n",
        "            role_path = os.path.join(roles_directory, role)\n",
        "            if os.path.isdir(role_path):\n",
        "                readme_file = os.path.join(role_path, \"README.md\")\n",
        "                if os.path.exists(readme_file):\n",
        "                    try:\n",
        "                        with open(readme_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                            content = f.read()\n",
        "                        knowledge_base[role] = content\n",
        "                        print(f\"Extracted README.md for role: {role}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error reading {readme_file}: {e}\")\n",
        "                else:\n",
        "                    print(f\"README.md not found for role: {role}\")\n",
        "    else:\n",
        "        print(\"Roles directory not found!\")\n",
        "    return knowledge_base\n",
        "\n",
        "knowledge_base = extract_role_contents(roles_dir)\n",
        "print(f\"Extracted content for {len(knowledge_base)} role(s).\")\n",
        "\n",
        "\n",
        "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def build_faiss_index(knowledge_base):\n",
        "    texts = []\n",
        "    role_names = []\n",
        "    for role, content in knowledge_base.items():\n",
        "        texts.append(content)\n",
        "        role_names.append(role)\n",
        "    embeddings = encoder.encode(texts, convert_to_numpy=True)\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(embeddings)\n",
        "    return index, role_names\n",
        "\n",
        "faiss_index, role_names = build_faiss_index(knowledge_base)\n",
        "print(\"FAISS index built for role contents.\")\n",
        "\n",
        "\n",
        "def find_relevant_roles(user_prompt, faiss_index, role_names):\n",
        "    query_embedding = encoder.encode([user_prompt], convert_to_numpy=True)\n",
        "    distances, indices = faiss_index.search(query_embedding, k=3)\n",
        "    return [role_names[idx] for idx in indices[0]]\n",
        "\n",
        "def get_role_content(role):\n",
        "    return knowledge_base.get(role, \"\")\n",
        "\n",
        "\n",
        "credentials = Credentials(\n",
        "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "    api_key=getpass.getpass(\"Enter your IBM WatsonX API Key: \"),\n",
        ")\n",
        "\n",
        "\n",
        "def generate_ansible_playbook(user_prompt, model_id):\n",
        "    matched_roles = find_relevant_roles(user_prompt, faiss_index, role_names)\n",
        "    print(f\"Relevant role(s) found: {matched_roles}\")\n",
        "\n",
        "\n",
        "    roles_data = {}\n",
        "    for role in matched_roles:\n",
        "        roles_data[role] = get_role_content(role)\n",
        "        print(f\"Using content from role: {role}\")\n",
        "\n",
        "\n",
        "    instruction = f\"\"\"\n",
        "You are an experienced Ansible expert who strictly produces valid YAML playbooks. I have extracted a set of Ansible roles from a GitHub repository, where each role is represented by its name and the complete content of its README.md file. Note that even though the reference may include up to three roles, you must only select and use the roles that are necessary to fulfill the user request, incorporating only the variables and parameters from those roles.\n",
        "Your task is to analyze the following reference roles and generate an optimized Ansible playbook that uses only the appropriate role(s) based on the variables listed in each role's content. The output must be a valid, complete Ansible playbook in YAML format following best practices. Do not include any extra commentary or explanation—only output the YAML playbook.\n",
        "Reference Roles:\n",
        "{roles_data}\n",
        "\n",
        "    User Request: {user_prompt}\n",
        "    \"\"\"\n",
        "\n",
        "    parameters = {\n",
        "        GenParams.DECODING_METHOD: \"greedy\",\n",
        "        GenParams.MAX_NEW_TOKENS: 8000,\n",
        "        GenParams.STOP_SEQUENCES: [\"<end·of·code>\"]\n",
        "    }\n",
        "\n",
        "    model = ModelInference(\n",
        "        model_id=model_id,\n",
        "        params=parameters,\n",
        "        credentials=credentials,\n",
        "        # project_id=\"68ff7a4b-b299-4b8f-9211-63185899dee6\"\n",
        "        project_id = getpass.getpass(\"Enter your Project Id: \")\n",
        "    )\n",
        "\n",
        "    print(\"Sending instruction to WatsonX AI model...\")\n",
        "    result = model.generate_text(instruction)\n",
        "    print(\"================================\")\n",
        "    print(f\"Playbook generated by: {model_id}\")\n",
        "    print(\"================================\")\n",
        "    return result\n",
        "\n",
        "user_input = \"Create a playbook to install a client on remote VMs using the appropriate roles. Once the server is installed it should create the dsm.sys and dsm.opt files\"\n",
        "generated_playbook = generate_ansible_playbook(user_input, \"meta-llama/llama-3-1-70b-instruct\")\n",
        "print(\"Generated Playbook:\")\n",
        "print(generated_playbook)"
      ],
      "metadata": {
        "id": "orDMCT691QW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7N6cw17V1J7N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}